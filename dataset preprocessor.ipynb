{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pcp_module import process_audio_and_save_pcp\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import multiprocessing\n",
    "\n",
    "def process_annotation_file(annotation_file_path):\n",
    "    \"\"\"Process a single annotation file and return the processed DataFrame.\"\"\"\n",
    "    with open(annotation_file_path, 'r') as file:\n",
    "        lines = file.readlines()[7:]    \n",
    "        arff_content = [line.strip().strip(\"'\").split(\",\") for line in lines]\n",
    "    \n",
    "    annotations_df = pd.DataFrame(arff_content, columns=['start_time', 'bar', 'beat', 'chord'])\n",
    "    annotations_df['start_time'] = annotations_df['start_time'].astype(float)\n",
    "    annotations_df['bar'] = annotations_df['bar'].astype(int)\n",
    "    annotations_df['beat'] = annotations_df['beat'].astype(int)\n",
    "    annotations_df['chord'] = annotations_df['chord'].str.strip(\"'\")\n",
    "    annotations_df['end_time'] = annotations_df['start_time'].shift(-1)\n",
    "    annotations_df = annotations_df.ffill()\n",
    "    \n",
    "    return annotations_df\n",
    "\n",
    "def process_file_pair(args):\n",
    "    \"\"\"Process a pair of audio and annotation files.\"\"\"\n",
    "    audio_file_name, annotations_file_name, dataset_location, annotations_dir_loc, output_dir = args\n",
    "    try:\n",
    "        # Process annotation file\n",
    "        annotation_file_path = os.path.join(annotations_dir_loc, annotations_file_name)\n",
    "        annotations_df = process_annotation_file(annotation_file_path)\n",
    "        \n",
    "        # Process audio and save PCP\n",
    "        process_audio_and_save_pcp(audio_file_name, dataset_location, annotations_df, output_dir)\n",
    "        \n",
    "        return f\"Successfully processed {audio_file_name}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error processing {audio_file_name}: {str(e)}\"\n",
    "\n",
    "def main():\n",
    "    # Configuration\n",
    "    dataset_location = \"./dataset/audio-mixes/\"\n",
    "    output_dir = 'extracted mfcc annotations'\n",
    "    annotations_dir_loc = \"./dataset/annotations/\"\n",
    "    \n",
    "    # Get file lists\n",
    "    audio_file_names = [file for root, dirs, files in os.walk(dataset_location) for file in files]\n",
    "    arff_files = [file for root, dirs, files in os.walk(annotations_dir_loc) \n",
    "                  for file in files if file.endswith('beatinfo.arff')]\n",
    "    \n",
    "    # Prepare arguments for parallel processing\n",
    "    process_args = [\n",
    "        (audio_file, arff_file, dataset_location, annotations_dir_loc, output_dir)\n",
    "        for audio_file, arff_file in zip(audio_file_names, arff_files)\n",
    "    ]\n",
    "    \n",
    "    # Use all available logical processors\n",
    "    num_workers = os.cpu_count() \n",
    "    \n",
    "    # Initialize multiprocessing progress bar\n",
    "    multiprocessing.freeze_support()  # Needed for Windows\n",
    "    \n",
    "    # Process files in parallel with progress bar\n",
    "    with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "        # Submit all tasks\n",
    "        future_to_file = {\n",
    "            executor.submit(process_file_pair, args): args[0]\n",
    "            for args in process_args\n",
    "        }\n",
    "        \n",
    "        # Create progress bar\n",
    "        with tqdm(total=len(process_args), unit=' Files') as pbar:\n",
    "            for future in as_completed(future_to_file):\n",
    "                file_name = future_to_file[future]\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    if \"Error\" in result:\n",
    "                        print(f\"\\nWarning: {result}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nError processing {file_name}: {str(e)}\")\n",
    "                finally:\n",
    "                    pbar.update(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pcp_module import process_audio_and_save_pcp\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_annotation_file(annotation_file_path):\n",
    "    \"\"\"Process a single annotation file and return the processed DataFrame.\"\"\"\n",
    "    with open(annotation_file_path, 'r') as file:\n",
    "        lines = file.readlines()[7:]    \n",
    "        arff_content = [line.strip().strip(\"'\").split(\",\") for line in lines]\n",
    "    \n",
    "    annotations_df = pd.DataFrame(arff_content, columns=['start_time', 'bar', 'beat', 'chord'])\n",
    "    annotations_df['start_time'] = annotations_df['start_time'].astype(float)\n",
    "    annotations_df['bar'] = annotations_df['bar'].astype(int)\n",
    "    annotations_df['beat'] = annotations_df['beat'].astype(int)\n",
    "    annotations_df['chord'] = annotations_df['chord'].str.strip(\"'\")\n",
    "    annotations_df['end_time'] = annotations_df['start_time'].shift(-1)\n",
    "    annotations_df = annotations_df.ffill()\n",
    "    \n",
    "    return annotations_df\n",
    "\n",
    "def process_file_pair(args):\n",
    "    \"\"\"Process a pair of audio and annotation files.\"\"\"\n",
    "    audio_file_name, annotations_file_name, dataset_location, annotations_dir_loc, output_dir = args\n",
    "    try:\n",
    "        # Process annotation file\n",
    "        annotation_file_path = os.path.join(annotations_dir_loc, annotations_file_name)\n",
    "        annotations_df = process_annotation_file(annotation_file_path)\n",
    "        \n",
    "        # Process audio and save PCP\n",
    "        process_audio_and_save_pcp(audio_file_name, dataset_location, annotations_df, output_dir)\n",
    "        \n",
    "        return f\"Successfully processed {audio_file_name}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error processing {audio_file_name}: {str(e)}\"\n",
    "\n",
    "def main():\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    if physical_devices:\n",
    "        try:\n",
    "            # Enable memory growth to avoid allocating all GPU memory at once\n",
    "            for device in physical_devices:\n",
    "                tf.config.experimental.set_memory_growth(device, True)\n",
    "            print(f\"GPU devices available: {len(physical_devices)}\")\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Error configuring GPU: {e}\")\n",
    "    else:\n",
    "        print(\"No GPU devices found. Running on CPU.\")\n",
    "    # Configuration\n",
    "    dataset_location = \"./dataset/audio-mixes/\"\n",
    "    output_dir = 'extracted annotations'\n",
    "    annotations_dir_loc = \"./dataset/annotations/\"\n",
    "    \n",
    "    # Get file lists\n",
    "    audio_file_names = [file for root, dirs, files in os.walk(dataset_location) for file in files]\n",
    "    arff_files = [file for root, dirs, files in os.walk(annotations_dir_loc) \n",
    "                  for file in files if file.endswith('beatinfo.arff')]\n",
    "    \n",
    "    # Prepare arguments for parallel processing\n",
    "    process_args = [\n",
    "        (audio_file, arff_file, dataset_location, annotations_dir_loc, output_dir)\n",
    "        for audio_file, arff_file in zip(audio_file_names, arff_files)\n",
    "    ]\n",
    "    \n",
    "    # Calculate optimal number of workers\n",
    "    num_workers = min(len(process_args), os.cpu_count() * 2.5)  # 2 threads per CPU core\n",
    "    \n",
    "    # Process files in parallel with progress bar\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        # Submit all tasks\n",
    "        future_to_file = {\n",
    "            executor.submit(process_file_pair, args): args[0]\n",
    "            for args in process_args\n",
    "        }\n",
    "        \n",
    "        # Create progress bar\n",
    "        with tqdm(total=len(process_args), unit=' Files') as pbar:\n",
    "            for future in as_completed(future_to_file):\n",
    "                file_name = future_to_file[future]\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    if \"Error\" in result:\n",
    "                        print(f\"\\nWarning: {result}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nError processing {file_name}: {str(e)}\")\n",
    "                finally:\n",
    "                    pbar.update(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_location = \"./dataset/audio-mixes/\"\n",
    "output_dir = 'extracted annotations'\n",
    "annotations_dir_loc = \"./dataset/annotations/\"\n",
    "\n",
    "audio_file_names = [file for root, dirs, files in os.walk(dataset_location) for file in files]\n",
    "arff_files = [file for root, dirs, files in os.walk(annotations_dir_loc) for file in files if file.endswith('beatinfo.arff')]\n",
    "for audio_file_name, annotations_file_name in tqdm(zip(audio_file_names, arff_files), unit=' Files'):\n",
    "    with open(os.path.join(annotations_dir_loc,annotations_file_name), 'r') as file:\n",
    "        lines = file.readlines()[7:]    \n",
    "        arff_content = [line.strip().strip(\"'\").split(\",\") for line in lines]\n",
    "    annotations_df = pd.DataFrame(arff_content, columns=['start_time', 'bar', 'beat', 'chord'])\n",
    "    annotations_df['start_time'] = annotations_df['start_time'].astype(float)\n",
    "    annotations_df['bar'] = annotations_df['bar'].astype(int)\n",
    "    annotations_df['beat'] = annotations_df['beat'].astype(int)\n",
    "    annotations_df['chord'] = annotations_df['chord'].str.strip(\"'\")\n",
    "    annotations_df['end_time'] = annotations_df['start_time'].shift(-1)\n",
    "    annotations_df = annotations_df.ffill()\n",
    "    process_audio_and_save_pcp(audio_file_name, dataset_location, annotations_df, output_dir)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
